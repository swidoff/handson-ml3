{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"datasets/timeseries.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "\n",
    "## Take a Quick Look at the Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2yr_yield_90d_change</th>\n",
       "      <th>T10y2y_90d_change</th>\n",
       "      <th>high_yield_90d_change</th>\n",
       "      <th>vug_vtv_60d_ret</th>\n",
       "      <th>t1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>build_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-01-03</th>\n",
       "      <td>0.105012</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.036786</td>\n",
       "      <td>-0.017685</td>\n",
       "      <td>2006-03-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-04</th>\n",
       "      <td>0.122249</td>\n",
       "      <td>-1.428571</td>\n",
       "      <td>0.038835</td>\n",
       "      <td>-0.024207</td>\n",
       "      <td>2006-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-05</th>\n",
       "      <td>0.146949</td>\n",
       "      <td>-1.428571</td>\n",
       "      <td>0.042718</td>\n",
       "      <td>-0.023621</td>\n",
       "      <td>2006-04-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-06</th>\n",
       "      <td>0.150432</td>\n",
       "      <td>-1.733333</td>\n",
       "      <td>0.052478</td>\n",
       "      <td>-0.026593</td>\n",
       "      <td>2006-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-09</th>\n",
       "      <td>0.150432</td>\n",
       "      <td>-1.733333</td>\n",
       "      <td>0.048497</td>\n",
       "      <td>-0.028333</td>\n",
       "      <td>2006-04-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-10</th>\n",
       "      <td>0.137255</td>\n",
       "      <td>-1.741935</td>\n",
       "      <td>0.058140</td>\n",
       "      <td>-0.024177</td>\n",
       "      <td>2006-04-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-11</th>\n",
       "      <td>0.130435</td>\n",
       "      <td>-1.733333</td>\n",
       "      <td>0.073786</td>\n",
       "      <td>-0.022117</td>\n",
       "      <td>2006-04-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-12</th>\n",
       "      <td>0.137184</td>\n",
       "      <td>-1.733333</td>\n",
       "      <td>0.074510</td>\n",
       "      <td>-0.025376</td>\n",
       "      <td>2006-04-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-13</th>\n",
       "      <td>0.111922</td>\n",
       "      <td>-1.714286</td>\n",
       "      <td>0.057030</td>\n",
       "      <td>-0.026654</td>\n",
       "      <td>2006-04-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-17</th>\n",
       "      <td>0.111922</td>\n",
       "      <td>-1.714286</td>\n",
       "      <td>0.051181</td>\n",
       "      <td>-0.022997</td>\n",
       "      <td>2006-04-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-18</th>\n",
       "      <td>0.104496</td>\n",
       "      <td>-1.857143</td>\n",
       "      <td>0.044966</td>\n",
       "      <td>-0.022973</td>\n",
       "      <td>2006-04-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-19</th>\n",
       "      <td>0.104496</td>\n",
       "      <td>-1.878788</td>\n",
       "      <td>0.036786</td>\n",
       "      <td>-0.026164</td>\n",
       "      <td>2006-04-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-20</th>\n",
       "      <td>0.095923</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.032978</td>\n",
       "      <td>-0.027348</td>\n",
       "      <td>2006-04-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-23</th>\n",
       "      <td>0.106024</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.036929</td>\n",
       "      <td>-0.024139</td>\n",
       "      <td>2006-04-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-24</th>\n",
       "      <td>0.083832</td>\n",
       "      <td>-1.851852</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>-0.023415</td>\n",
       "      <td>2006-04-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-25</th>\n",
       "      <td>0.098439</td>\n",
       "      <td>-1.538462</td>\n",
       "      <td>0.055609</td>\n",
       "      <td>-0.024862</td>\n",
       "      <td>2006-04-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-26</th>\n",
       "      <td>0.121284</td>\n",
       "      <td>-1.555556</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>-0.027148</td>\n",
       "      <td>2006-04-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-27</th>\n",
       "      <td>0.114889</td>\n",
       "      <td>-1.833333</td>\n",
       "      <td>0.041746</td>\n",
       "      <td>-0.024521</td>\n",
       "      <td>2006-04-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-30</th>\n",
       "      <td>0.102564</td>\n",
       "      <td>-1.833333</td>\n",
       "      <td>0.035748</td>\n",
       "      <td>-0.024574</td>\n",
       "      <td>2006-04-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-31</th>\n",
       "      <td>0.102326</td>\n",
       "      <td>-1.666667</td>\n",
       "      <td>0.033962</td>\n",
       "      <td>-0.028930</td>\n",
       "      <td>2006-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-01</th>\n",
       "      <td>0.104287</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.041509</td>\n",
       "      <td>-0.039777</td>\n",
       "      <td>2006-04-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-02</th>\n",
       "      <td>0.105505</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.049336</td>\n",
       "      <td>-0.036010</td>\n",
       "      <td>2006-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-03</th>\n",
       "      <td>0.093501</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>-0.040809</td>\n",
       "      <td>2006-05-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-06</th>\n",
       "      <td>0.086364</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.022901</td>\n",
       "      <td>-0.040354</td>\n",
       "      <td>2006-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-07</th>\n",
       "      <td>0.090498</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.020814</td>\n",
       "      <td>-0.036290</td>\n",
       "      <td>2006-05-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-08</th>\n",
       "      <td>0.090703</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.022642</td>\n",
       "      <td>-0.041405</td>\n",
       "      <td>2006-05-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-09</th>\n",
       "      <td>0.099548</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.028599</td>\n",
       "      <td>-0.036590</td>\n",
       "      <td>2006-05-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-10</th>\n",
       "      <td>0.114994</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.028382</td>\n",
       "      <td>-0.038524</td>\n",
       "      <td>2006-05-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-13</th>\n",
       "      <td>0.114994</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.028329</td>\n",
       "      <td>-0.035949</td>\n",
       "      <td>2006-05-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-14</th>\n",
       "      <td>0.103371</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.024367</td>\n",
       "      <td>-0.039717</td>\n",
       "      <td>2006-05-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-15</th>\n",
       "      <td>0.100784</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>-0.036764</td>\n",
       "      <td>2006-05-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-16</th>\n",
       "      <td>0.105028</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.030132</td>\n",
       "      <td>-0.037122</td>\n",
       "      <td>2006-05-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-17</th>\n",
       "      <td>0.087346</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.009443</td>\n",
       "      <td>-0.034717</td>\n",
       "      <td>2006-05-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-21</th>\n",
       "      <td>0.087346</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.016997</td>\n",
       "      <td>-0.027749</td>\n",
       "      <td>2006-05-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-22</th>\n",
       "      <td>0.102679</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.005676</td>\n",
       "      <td>-0.026233</td>\n",
       "      <td>2006-05-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-23</th>\n",
       "      <td>0.091620</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-0.003752</td>\n",
       "      <td>-0.028393</td>\n",
       "      <td>2006-05-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-24</th>\n",
       "      <td>0.116071</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-0.013072</td>\n",
       "      <td>-0.031595</td>\n",
       "      <td>2006-05-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-27</th>\n",
       "      <td>0.109010</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-0.009320</td>\n",
       "      <td>-0.034748</td>\n",
       "      <td>2006-05-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-28</th>\n",
       "      <td>0.088106</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-0.014953</td>\n",
       "      <td>-0.030355</td>\n",
       "      <td>2006-05-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-03-01</th>\n",
       "      <td>0.068357</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-0.001864</td>\n",
       "      <td>-0.036836</td>\n",
       "      <td>2006-05-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-03-02</th>\n",
       "      <td>0.077178</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.009285</td>\n",
       "      <td>-0.037573</td>\n",
       "      <td>2006-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-03-03</th>\n",
       "      <td>0.078603</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.020352</td>\n",
       "      <td>-0.039029</td>\n",
       "      <td>2006-05-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-03-06</th>\n",
       "      <td>0.078603</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.046253</td>\n",
       "      <td>-0.038889</td>\n",
       "      <td>2006-05-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-03-07</th>\n",
       "      <td>0.076170</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.035023</td>\n",
       "      <td>-0.035892</td>\n",
       "      <td>2006-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-03-08</th>\n",
       "      <td>0.073913</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.027498</td>\n",
       "      <td>-0.037526</td>\n",
       "      <td>2006-06-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-03-09</th>\n",
       "      <td>0.054407</td>\n",
       "      <td>-1.789474</td>\n",
       "      <td>0.009099</td>\n",
       "      <td>-0.043195</td>\n",
       "      <td>2006-06-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-03-10</th>\n",
       "      <td>0.058632</td>\n",
       "      <td>-1.619048</td>\n",
       "      <td>0.018215</td>\n",
       "      <td>-0.043661</td>\n",
       "      <td>2006-06-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-03-13</th>\n",
       "      <td>0.058632</td>\n",
       "      <td>-1.600000</td>\n",
       "      <td>0.023615</td>\n",
       "      <td>-0.041839</td>\n",
       "      <td>2006-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-03-14</th>\n",
       "      <td>0.067612</td>\n",
       "      <td>-1.294118</td>\n",
       "      <td>0.014625</td>\n",
       "      <td>-0.046338</td>\n",
       "      <td>2006-06-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-03-15</th>\n",
       "      <td>0.037158</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.020018</td>\n",
       "      <td>-0.045741</td>\n",
       "      <td>2006-06-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-03-16</th>\n",
       "      <td>0.054765</td>\n",
       "      <td>-0.933333</td>\n",
       "      <td>0.001823</td>\n",
       "      <td>-0.047503</td>\n",
       "      <td>2006-06-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-03-17</th>\n",
       "      <td>0.046205</td>\n",
       "      <td>-1.142857</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.041458</td>\n",
       "      <td>2006-06-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-03-20</th>\n",
       "      <td>0.032787</td>\n",
       "      <td>-1.142857</td>\n",
       "      <td>-0.007260</td>\n",
       "      <td>-0.040316</td>\n",
       "      <td>2006-06-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-03-21</th>\n",
       "      <td>0.039474</td>\n",
       "      <td>-1.600000</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>-0.036157</td>\n",
       "      <td>2006-06-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-03-22</th>\n",
       "      <td>0.065646</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.010969</td>\n",
       "      <td>-0.032092</td>\n",
       "      <td>2006-06-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-03-23</th>\n",
       "      <td>0.081229</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.007246</td>\n",
       "      <td>-0.033201</td>\n",
       "      <td>2006-06-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-03-24</th>\n",
       "      <td>0.070175</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.007339</td>\n",
       "      <td>-0.036455</td>\n",
       "      <td>2006-06-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-03-27</th>\n",
       "      <td>0.072448</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.005460</td>\n",
       "      <td>-0.029225</td>\n",
       "      <td>2006-06-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-03-28</th>\n",
       "      <td>0.088496</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.029091</td>\n",
       "      <td>-0.037444</td>\n",
       "      <td>2006-06-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-03-29</th>\n",
       "      <td>0.098146</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.049225</td>\n",
       "      <td>-0.036071</td>\n",
       "      <td>2006-06-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-03-30</th>\n",
       "      <td>0.100218</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.061818</td>\n",
       "      <td>-0.042989</td>\n",
       "      <td>2006-06-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-03-31</th>\n",
       "      <td>0.107104</td>\n",
       "      <td>-0.857143</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>-0.045550</td>\n",
       "      <td>2006-06-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-04-03</th>\n",
       "      <td>0.107104</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.061706</td>\n",
       "      <td>-0.049028</td>\n",
       "      <td>2006-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-04-04</th>\n",
       "      <td>0.099352</td>\n",
       "      <td>-1.200000</td>\n",
       "      <td>0.063463</td>\n",
       "      <td>-0.045172</td>\n",
       "      <td>2006-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-04-05</th>\n",
       "      <td>0.090713</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>0.052394</td>\n",
       "      <td>-0.043661</td>\n",
       "      <td>2006-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-04-06</th>\n",
       "      <td>0.077754</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>0.072202</td>\n",
       "      <td>-0.049400</td>\n",
       "      <td>2006-07-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-04-07</th>\n",
       "      <td>0.098712</td>\n",
       "      <td>-0.117647</td>\n",
       "      <td>0.093525</td>\n",
       "      <td>-0.056255</td>\n",
       "      <td>2006-07-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-04-10</th>\n",
       "      <td>0.089744</td>\n",
       "      <td>-0.222222</td>\n",
       "      <td>0.080429</td>\n",
       "      <td>-0.058021</td>\n",
       "      <td>2006-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-04-11</th>\n",
       "      <td>0.100967</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066012</td>\n",
       "      <td>-0.062556</td>\n",
       "      <td>2006-07-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-04-12</th>\n",
       "      <td>0.098925</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.069088</td>\n",
       "      <td>-0.069346</td>\n",
       "      <td>2006-07-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-04-13</th>\n",
       "      <td>0.126474</td>\n",
       "      <td>-0.352941</td>\n",
       "      <td>0.079435</td>\n",
       "      <td>-0.067688</td>\n",
       "      <td>2006-07-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-04-17</th>\n",
       "      <td>0.108395</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.067019</td>\n",
       "      <td>-0.066095</td>\n",
       "      <td>2006-07-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-04-18</th>\n",
       "      <td>0.102784</td>\n",
       "      <td>-0.095238</td>\n",
       "      <td>0.078153</td>\n",
       "      <td>-0.062220</td>\n",
       "      <td>2006-07-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-04-19</th>\n",
       "      <td>0.102063</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.082819</td>\n",
       "      <td>-0.064660</td>\n",
       "      <td>2006-07-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-04-20</th>\n",
       "      <td>0.106176</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.093722</td>\n",
       "      <td>-0.065887</td>\n",
       "      <td>2006-07-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-04-21</th>\n",
       "      <td>0.114347</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>-0.064976</td>\n",
       "      <td>2006-07-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-04-24</th>\n",
       "      <td>0.112069</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.067257</td>\n",
       "      <td>-0.062706</td>\n",
       "      <td>2006-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-04-25</th>\n",
       "      <td>0.100967</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.082529</td>\n",
       "      <td>-0.072166</td>\n",
       "      <td>2006-07-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-04-26</th>\n",
       "      <td>0.110874</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.100618</td>\n",
       "      <td>-0.074701</td>\n",
       "      <td>2006-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-04-27</th>\n",
       "      <td>0.125666</td>\n",
       "      <td>1.058824</td>\n",
       "      <td>0.100441</td>\n",
       "      <td>-0.070718</td>\n",
       "      <td>2006-07-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-04-28</th>\n",
       "      <td>0.108225</td>\n",
       "      <td>1.809524</td>\n",
       "      <td>0.104332</td>\n",
       "      <td>-0.060528</td>\n",
       "      <td>2006-07-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-05-01</th>\n",
       "      <td>0.108225</td>\n",
       "      <td>1.809524</td>\n",
       "      <td>0.114537</td>\n",
       "      <td>-0.072727</td>\n",
       "      <td>2006-07-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-05-02</th>\n",
       "      <td>0.127018</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.107489</td>\n",
       "      <td>-0.066389</td>\n",
       "      <td>2006-07-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-05-03</th>\n",
       "      <td>0.118407</td>\n",
       "      <td>1.809524</td>\n",
       "      <td>0.108963</td>\n",
       "      <td>-0.063889</td>\n",
       "      <td>2006-07-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-05-04</th>\n",
       "      <td>0.120172</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.120141</td>\n",
       "      <td>-0.066024</td>\n",
       "      <td>2006-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-05-05</th>\n",
       "      <td>0.113369</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.124777</td>\n",
       "      <td>-0.069165</td>\n",
       "      <td>2006-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-05-08</th>\n",
       "      <td>0.113369</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.132616</td>\n",
       "      <td>-0.066264</td>\n",
       "      <td>2006-08-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-05-09</th>\n",
       "      <td>0.135338</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.063958</td>\n",
       "      <td>2006-08-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-05-10</th>\n",
       "      <td>0.142241</td>\n",
       "      <td>1.047619</td>\n",
       "      <td>0.123545</td>\n",
       "      <td>-0.066542</td>\n",
       "      <td>2006-08-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-05-11</th>\n",
       "      <td>0.147910</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.126447</td>\n",
       "      <td>-0.065136</td>\n",
       "      <td>2006-08-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-05-12</th>\n",
       "      <td>0.138741</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.138053</td>\n",
       "      <td>-0.070358</td>\n",
       "      <td>2006-08-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-05-15</th>\n",
       "      <td>0.138741</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.134991</td>\n",
       "      <td>-0.068709</td>\n",
       "      <td>2006-08-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-05-16</th>\n",
       "      <td>0.123404</td>\n",
       "      <td>1.555556</td>\n",
       "      <td>0.124777</td>\n",
       "      <td>-0.062662</td>\n",
       "      <td>2006-08-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-05-17</th>\n",
       "      <td>0.110638</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.130973</td>\n",
       "      <td>-0.069470</td>\n",
       "      <td>2006-08-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-05-18</th>\n",
       "      <td>0.123932</td>\n",
       "      <td>1.454545</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>-0.067602</td>\n",
       "      <td>2006-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-05-19</th>\n",
       "      <td>0.133333</td>\n",
       "      <td>1.272727</td>\n",
       "      <td>0.101877</td>\n",
       "      <td>-0.061000</td>\n",
       "      <td>2006-08-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-05-22</th>\n",
       "      <td>0.133333</td>\n",
       "      <td>1.272727</td>\n",
       "      <td>0.096257</td>\n",
       "      <td>-0.049603</td>\n",
       "      <td>2006-08-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-05-23</th>\n",
       "      <td>0.131607</td>\n",
       "      <td>1.636364</td>\n",
       "      <td>0.109026</td>\n",
       "      <td>-0.049632</td>\n",
       "      <td>2006-08-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-05-24</th>\n",
       "      <td>0.137634</td>\n",
       "      <td>1.636364</td>\n",
       "      <td>0.117012</td>\n",
       "      <td>-0.055029</td>\n",
       "      <td>2006-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-05-25</th>\n",
       "      <td>0.122449</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.127583</td>\n",
       "      <td>-0.053829</td>\n",
       "      <td>2006-08-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            2yr_yield_90d_change  T10y2y_90d_change  high_yield_90d_change  vug_vtv_60d_ret         t1\n",
       "build_date                                                                                            \n",
       "2006-01-03              0.105012          -2.000000               0.036786        -0.017685 2006-03-30\n",
       "2006-01-04              0.122249          -1.428571               0.038835        -0.024207 2006-03-31\n",
       "2006-01-05              0.146949          -1.428571               0.042718        -0.023621 2006-04-03\n",
       "2006-01-06              0.150432          -1.733333               0.052478        -0.026593 2006-04-04\n",
       "2006-01-09              0.150432          -1.733333               0.048497        -0.028333 2006-04-05\n",
       "2006-01-10              0.137255          -1.741935               0.058140        -0.024177 2006-04-06\n",
       "2006-01-11              0.130435          -1.733333               0.073786        -0.022117 2006-04-07\n",
       "2006-01-12              0.137184          -1.733333               0.074510        -0.025376 2006-04-10\n",
       "2006-01-13              0.111922          -1.714286               0.057030        -0.026654 2006-04-11\n",
       "2006-01-17              0.111922          -1.714286               0.051181        -0.022997 2006-04-12\n",
       "2006-01-18              0.104496          -1.857143               0.044966        -0.022973 2006-04-13\n",
       "2006-01-19              0.104496          -1.878788               0.036786        -0.026164 2006-04-17\n",
       "2006-01-20              0.095923          -2.000000               0.032978        -0.027348 2006-04-18\n",
       "2006-01-23              0.106024          -2.000000               0.036929        -0.024139 2006-04-19\n",
       "2006-01-24              0.083832          -1.851852               0.032787        -0.023415 2006-04-20\n",
       "2006-01-25              0.098439          -1.538462               0.055609        -0.024862 2006-04-21\n",
       "2006-01-26              0.121284          -1.555556               0.057143        -0.027148 2006-04-24\n",
       "2006-01-27              0.114889          -1.833333               0.041746        -0.024521 2006-04-25\n",
       "2006-01-30              0.102564          -1.833333               0.035748        -0.024574 2006-04-26\n",
       "2006-01-31              0.102326          -1.666667               0.033962        -0.028930 2006-04-27\n",
       "2006-02-01              0.104287          -2.000000               0.041509        -0.039777 2006-04-28\n",
       "2006-02-02              0.105505          -2.000000               0.049336        -0.036010 2006-05-01\n",
       "2006-02-03              0.093501          -2.000000               0.036364        -0.040809 2006-05-02\n",
       "2006-02-06              0.086364          -2.000000               0.022901        -0.040354 2006-05-03\n",
       "2006-02-07              0.090498          -2.000000               0.020814        -0.036290 2006-05-04\n",
       "2006-02-08              0.090703          -2.000000               0.022642        -0.041405 2006-05-05\n",
       "2006-02-09              0.099548          -2.000000               0.028599        -0.036590 2006-05-08\n",
       "2006-02-10              0.114994          -2.000000               0.028382        -0.038524 2006-05-09\n",
       "2006-02-13              0.114994          -2.000000               0.028329        -0.035949 2006-05-10\n",
       "2006-02-14              0.103371          -2.000000               0.024367        -0.039717 2006-05-11\n",
       "2006-02-15              0.100784          -2.000000               0.026316        -0.036764 2006-05-12\n",
       "2006-02-16              0.105028          -2.000000               0.030132        -0.037122 2006-05-15\n",
       "2006-02-17              0.087346          -2.000000               0.009443        -0.034717 2006-05-16\n",
       "2006-02-21              0.087346          -2.000000               0.016997        -0.027749 2006-05-17\n",
       "2006-02-22              0.102679          -2.000000               0.005676        -0.026233 2006-05-18\n",
       "2006-02-23              0.091620          -2.000000              -0.003752        -0.028393 2006-05-19\n",
       "2006-02-24              0.116071          -2.000000              -0.013072        -0.031595 2006-05-22\n",
       "2006-02-27              0.109010          -2.000000              -0.009320        -0.034748 2006-05-23\n",
       "2006-02-28              0.088106          -2.000000              -0.014953        -0.030355 2006-05-24\n",
       "2006-03-01              0.068357          -2.000000              -0.001864        -0.036836 2006-05-25\n",
       "2006-03-02              0.077178          -2.000000               0.009285        -0.037573 2006-05-26\n",
       "2006-03-03              0.078603          -2.000000               0.020352        -0.039029 2006-05-30\n",
       "2006-03-06              0.078603          -2.000000               0.046253        -0.038889 2006-05-31\n",
       "2006-03-07              0.076170          -2.000000               0.035023        -0.035892 2006-06-01\n",
       "2006-03-08              0.073913          -2.000000               0.027498        -0.037526 2006-06-02\n",
       "2006-03-09              0.054407          -1.789474               0.009099        -0.043195 2006-06-05\n",
       "2006-03-10              0.058632          -1.619048               0.018215        -0.043661 2006-06-06\n",
       "2006-03-13              0.058632          -1.600000               0.023615        -0.041839 2006-06-07\n",
       "2006-03-14              0.067612          -1.294118               0.014625        -0.046338 2006-06-08\n",
       "2006-03-15              0.037158          -1.000000               0.020018        -0.045741 2006-06-09\n",
       "2006-03-16              0.054765          -0.933333               0.001823        -0.047503 2006-06-12\n",
       "2006-03-17              0.046205          -1.142857              -0.001813        -0.041458 2006-06-13\n",
       "2006-03-20              0.032787          -1.142857              -0.007260        -0.040316 2006-06-14\n",
       "2006-03-21              0.039474          -1.600000               0.003623        -0.036157 2006-06-15\n",
       "2006-03-22              0.065646          -2.000000               0.010969        -0.032092 2006-06-16\n",
       "2006-03-23              0.081229          -2.000000               0.007246        -0.033201 2006-06-19\n",
       "2006-03-24              0.070175          -2.000000               0.007339        -0.036455 2006-06-20\n",
       "2006-03-27              0.072448          -2.000000               0.005460        -0.029225 2006-06-21\n",
       "2006-03-28              0.088496          -2.000000               0.029091        -0.037444 2006-06-22\n",
       "2006-03-29              0.098146          -2.000000               0.049225        -0.036071 2006-06-23\n",
       "2006-03-30              0.100218          -2.000000               0.061818        -0.042989 2006-06-26\n",
       "2006-03-31              0.107104          -0.857143               0.054348        -0.045550 2006-06-27\n",
       "2006-04-03              0.107104          -0.666667               0.061706        -0.049028 2006-06-28\n",
       "2006-04-04              0.099352          -1.200000               0.063463        -0.045172 2006-06-29\n",
       "2006-04-05              0.090713          -0.800000               0.052394        -0.043661 2006-06-30\n",
       "2006-04-06              0.077754          -0.800000               0.072202        -0.049400 2006-07-03\n",
       "2006-04-07              0.098712          -0.117647               0.093525        -0.056255 2006-07-05\n",
       "2006-04-10              0.089744          -0.222222               0.080429        -0.058021 2006-07-06\n",
       "2006-04-11              0.100967           0.133333               0.066012        -0.062556 2006-07-07\n",
       "2006-04-12              0.098925          -0.666667               0.069088        -0.069346 2006-07-10\n",
       "2006-04-13              0.126474          -0.352941               0.079435        -0.067688 2006-07-11\n",
       "2006-04-17              0.108395          -0.200000               0.067019        -0.066095 2006-07-12\n",
       "2006-04-18              0.102784          -0.095238               0.078153        -0.062220 2006-07-13\n",
       "2006-04-19              0.102063           0.608696               0.082819        -0.064660 2006-07-14\n",
       "2006-04-20              0.106176           0.571429               0.093722        -0.065887 2006-07-17\n",
       "2006-04-21              0.114347           0.315789               0.074074        -0.064976 2006-07-18\n",
       "2006-04-24              0.112069           0.444444               0.067257        -0.062706 2006-07-19\n",
       "2006-04-25              0.100967           0.666667               0.082529        -0.072166 2006-07-20\n",
       "2006-04-26              0.110874           0.666667               0.100618        -0.074701 2006-07-21\n",
       "2006-04-27              0.125666           1.058824               0.100441        -0.070718 2006-07-24\n",
       "2006-04-28              0.108225           1.809524               0.104332        -0.060528 2006-07-25\n",
       "2006-05-01              0.108225           1.809524               0.114537        -0.072727 2006-07-26\n",
       "2006-05-02              0.127018           2.000000               0.107489        -0.066389 2006-07-27\n",
       "2006-05-03              0.118407           1.809524               0.108963        -0.063889 2006-07-28\n",
       "2006-05-04              0.120172           2.000000               0.120141        -0.066024 2006-07-31\n",
       "2006-05-05              0.113369           2.000000               0.124777        -0.069165 2006-08-01\n",
       "2006-05-08              0.113369           2.000000               0.132616        -0.066264 2006-08-02\n",
       "2006-05-09              0.135338           1.333333               0.125000        -0.063958 2006-08-03\n",
       "2006-05-10              0.142241           1.047619               0.123545        -0.066542 2006-08-04\n",
       "2006-05-11              0.147910           1.000000               0.126447        -0.065136 2006-08-07\n",
       "2006-05-12              0.138741           1.600000               0.138053        -0.070358 2006-08-08\n",
       "2006-05-15              0.138741           1.600000               0.134991        -0.068709 2006-08-09\n",
       "2006-05-16              0.123404           1.555556               0.124777        -0.062662 2006-08-10\n",
       "2006-05-17              0.110638           1.500000               0.130973        -0.069470 2006-08-11\n",
       "2006-05-18              0.123932           1.454545               0.114286        -0.067602 2006-08-14\n",
       "2006-05-19              0.133333           1.272727               0.101877        -0.061000 2006-08-15\n",
       "2006-05-22              0.133333           1.272727               0.096257        -0.049603 2006-08-16\n",
       "2006-05-23              0.131607           1.636364               0.109026        -0.049632 2006-08-17\n",
       "2006-05-24              0.137634           1.636364               0.117012        -0.055029 2006-08-18\n",
       "2006-05-25              0.122449           1.600000               0.127583        -0.053829 2006-08-21"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2yr_yield_90d_change</th>\n",
       "      <th>T10y2y_90d_change</th>\n",
       "      <th>high_yield_90d_change</th>\n",
       "      <th>vug_vtv_60d_ret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4188.000000</td>\n",
       "      <td>4188.000000</td>\n",
       "      <td>4188.000000</td>\n",
       "      <td>4188.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.032690</td>\n",
       "      <td>-0.005079</td>\n",
       "      <td>0.005173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.433406</td>\n",
       "      <td>0.714401</td>\n",
       "      <td>0.116090</td>\n",
       "      <td>0.048890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.647799</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-0.196183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.169492</td>\n",
       "      <td>-0.261746</td>\n",
       "      <td>-0.078016</td>\n",
       "      <td>-0.019326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.029271</td>\n",
       "      <td>-0.066176</td>\n",
       "      <td>-0.015262</td>\n",
       "      <td>0.004006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.225417</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.030814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.338583</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.449213</td>\n",
       "      <td>0.223951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       2yr_yield_90d_change  T10y2y_90d_change  high_yield_90d_change  vug_vtv_60d_ret\n",
       "count           4188.000000        4188.000000            4188.000000      4188.000000\n",
       "mean              -0.000200          -0.032690              -0.005079         0.005173\n",
       "std                0.433406           0.714401               0.116090         0.048890\n",
       "min               -1.647799          -2.000000              -0.666667        -0.196183\n",
       "25%               -0.169492          -0.261746              -0.078016        -0.019326\n",
       "50%                0.029271          -0.066176              -0.015262         0.004006\n",
       "75%                0.222222           0.225417               0.064000         0.030814\n",
       "max                1.338583           2.000000               0.449213         0.223951"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)\n",
    "\n",
    "df.drop(columns=[\"t1\"]).hist(bins=50, figsize=(12, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import purged_kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_train, df_test = purged_kfold.train_test_split(df, df.t1, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3291, 838, 4129, 4188)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train), len(df_test), len(df_train) + len(df_test), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_X = df_train.drop([\"vug_vtv_60d_ret\", \"t1\"], axis=1)\n",
    "train_y = df_train.loc[:, \"vug_vtv_60d_ret\"]\n",
    "train_Y = df_train.loc[:, [\"vug_vtv_60d_ret\", \"t1\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discover and Visualize the Data to Gain Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "corr_matrix = df_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vug_vtv_60d_ret          1.000000\n",
       "T10y2y_90d_change        0.221856\n",
       "high_yield_90d_change    0.029721\n",
       "2yr_yield_90d_change    -0.223042\n",
       "Name: vug_vtv_60d_ret, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix[\"vug_vtv_60d_ret\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "scatter_matrix(df_train, figsize=(12, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_train.plot(kind=\"scatter\", x=\"2yr_yield_90d_change\", y=\"vug_vtv_60d_ret\", alpha=0.1, grid=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_train.plot(kind=\"scatter\", x=\"T10y2y_90d_change\", y=\"vug_vtv_60d_ret\", alpha=0.1, grid=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_train.plot(kind=\"scatter\", x=\"high_yield_90d_change\", y=\"vug_vtv_60d_ret\", alpha=0.1, grid=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "def preprocessing():\n",
    "    return Pipeline([(\"standardize\", StandardScaler()), ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "## Select and Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1005627065415633, 0.031973454127755443)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = make_pipeline(preprocessing(), LinearRegression())\n",
    "lin_reg.fit(train_X, train_y)\n",
    "predictions = lin_reg.predict(train_X)\n",
    "lin_r2 = r2_score(train_y, predictions)\n",
    "lin_rmse = mean_squared_error(train_y, predictions, squared=False)\n",
    "lin_r2, lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg_mean_squared_error</th>\n",
       "      <th>r2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.035193</td>\n",
       "      <td>-0.175435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.005469</td>\n",
       "      <td>0.206774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      neg_mean_squared_error  r2_score\n",
       "mean               -0.035193 -0.175435\n",
       "std                 0.005469  0.206774"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg_func = lambda: make_pipeline(preprocessing(), LinearRegression())\n",
    "scores = purged_kfold.cv_score(lin_reg_func, train_X, train_Y, n_folds=3, scoring=[\"neg_mean_squared_error\",\"r2_score\"])\n",
    "scores.agg([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9444760218916632, 0.007944094429669705)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = make_pipeline(preprocessing(), RandomForestRegressor())\n",
    "forest_reg.fit(train_X, train_y)\n",
    "predictions = forest_reg.predict(train_X)\n",
    "forest_r2 = r2_score(train_y, predictions)\n",
    "forest_rmse = mean_squared_error(train_y, predictions, squared=False)\n",
    "forest_r2, forest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg_mean_squared_error</th>\n",
       "      <th>r2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.040982</td>\n",
       "      <td>-0.645107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.004252</td>\n",
       "      <td>0.529071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      neg_mean_squared_error  r2_score\n",
       "mean               -0.040982 -0.645107\n",
       "std                 0.004252  0.529071"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_reg = lambda: make_pipeline(preprocessing(), RandomForestRegressor(random_state=42))\n",
    "forest_rmse = purged_kfold.cv_score(forest_reg, train_X, train_Y, n_folds=3, scoring=[\"neg_mean_squared_error\",\n",
    "                                                                                      \"r2_score\"])\n",
    "forest_rmse.agg([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11637182481215591, 0.03169121489405202)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svm_reg = make_pipeline(preprocessing(), SVR())\n",
    "svm_reg.fit(train_X, train_y)\n",
    "predictions = svm_reg.predict(train_X)\n",
    "svm_r2 = r2_score(train_y, predictions)\n",
    "svm_rmse = mean_squared_error(train_y, predictions, squared=False)\n",
    "svm_r2, svm_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg_mean_squared_error</th>\n",
       "      <th>r2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.032986</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.008031</td>\n",
       "      <td>0.047046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      neg_mean_squared_error  r2_score\n",
       "mean               -0.032986  0.000051\n",
       "std                 0.008031  0.047046"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_reg = lambda: make_pipeline(preprocessing(), SVR())\n",
    "svm_rmse = purged_kfold.cv_score(svm_reg, train_X, train_Y, n_folds=3, scoring=[\"neg_mean_squared_error\",\n",
    "                                                                                \"r2_score\"])\n",
    "svm_rmse.agg([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9008837291043885, 0.01061393900906928)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_reg = make_pipeline(preprocessing(), xgb.XGBRegressor())\n",
    "xgb_reg.fit(train_X, train_y)\n",
    "predictions = xgb_reg.predict(train_X)\n",
    "xgb_r2 = r2_score(train_y, predictions)\n",
    "xgb_rmse = mean_squared_error(train_y, predictions, squared=False)\n",
    "xgb_r2, xgb_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg_mean_squared_error</th>\n",
       "      <th>r2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.041638</td>\n",
       "      <td>-0.681789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.005612</td>\n",
       "      <td>0.506503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      neg_mean_squared_error  r2_score\n",
       "mean               -0.041638 -0.681789\n",
       "std                 0.005612  0.506503"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_reg = lambda: make_pipeline(preprocessing(), xgb.XGBRegressor())\n",
    "xgb_rmse = purged_kfold.cv_score(xgb_reg, train_X, train_Y, n_folds=3, scoring=[\"neg_mean_squared_error\",\n",
    "                                                                               \"r2_score\"])\n",
    "xgb_rmse.agg([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tune Your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "full_pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocessing()),\n",
    "    (\"random_forest\", RandomForestRegressor(random_state=42, max_features=None)),\n",
    "])\n",
    "param_grid = [\n",
    "    {\n",
    "        'random_forest__max_depth': [1, 2, 4],\n",
    "        'random_forest__n_estimators': [10, 100, 1000],\n",
    "    },\n",
    "]\n",
    "cv = purged_kfold.PurgedKFold(train_Y.t1, n_folds=3)\n",
    "cv_iter = cv.split(train_X, train_y)\n",
    "\n",
    "grid_search = GridSearchCV(full_pipeline, param_grid, cv=cv_iter, scoring='neg_root_mean_squared_error')\n",
    "_ = grid_search.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'random_forest__max_depth': 2, 'random_forest...</td>\n",
       "      <td>-0.035402</td>\n",
       "      <td>0.003840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'random_forest__max_depth': 1, 'random_forest...</td>\n",
       "      <td>-0.035437</td>\n",
       "      <td>0.005862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'random_forest__max_depth': 2, 'random_forest...</td>\n",
       "      <td>-0.035496</td>\n",
       "      <td>0.003872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'random_forest__max_depth': 1, 'random_forest...</td>\n",
       "      <td>-0.035503</td>\n",
       "      <td>0.005710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'random_forest__max_depth': 1, 'random_forest...</td>\n",
       "      <td>-0.035527</td>\n",
       "      <td>0.005666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'random_forest__max_depth': 2, 'random_forest...</td>\n",
       "      <td>-0.035594</td>\n",
       "      <td>0.003815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'random_forest__max_depth': 4, 'random_forest...</td>\n",
       "      <td>-0.037121</td>\n",
       "      <td>0.004088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'random_forest__max_depth': 4, 'random_forest...</td>\n",
       "      <td>-0.037309</td>\n",
       "      <td>0.004054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'random_forest__max_depth': 4, 'random_forest...</td>\n",
       "      <td>-0.037370</td>\n",
       "      <td>0.003633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params  mean_test_score  std_test_score\n",
       "3  {'random_forest__max_depth': 2, 'random_forest...        -0.035402        0.003840\n",
       "0  {'random_forest__max_depth': 1, 'random_forest...        -0.035437        0.005862\n",
       "5  {'random_forest__max_depth': 2, 'random_forest...        -0.035496        0.003872\n",
       "2  {'random_forest__max_depth': 1, 'random_forest...        -0.035503        0.005710\n",
       "1  {'random_forest__max_depth': 1, 'random_forest...        -0.035527        0.005666\n",
       "4  {'random_forest__max_depth': 2, 'random_forest...        -0.035594        0.003815\n",
       "8  {'random_forest__max_depth': 4, 'random_forest...        -0.037121        0.004088\n",
       "6  {'random_forest__max_depth': 4, 'random_forest...        -0.037309        0.004054\n",
       "7  {'random_forest__max_depth': 4, 'random_forest...        -0.037370        0.003633"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_res.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "cv_res.loc[:, [\"params\", \"mean_test_score\", \"std_test_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "full_pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocessing()),\n",
    "    (\"svr\", SVR()),\n",
    "])\n",
    "param_grid = [\n",
    "    # {'svr__kernel': ['linear'], 'svr__C': [10., 30., 100., 300., 1000.,\n",
    "    #                                        3000., 10000., 30000.0]},\n",
    "    {'svr__kernel': ['rbf'], 'svr__C': [1.0, 3.0, 10., 30., 100., 300.,\n",
    "                                        1000.0],\n",
    "     # 'svr__gamma': [0.01, 0.03, 0.1, 0.3, 1.0, 3.0]},\n",
    "     'svr__gamma': [1.5, 1.75, 2.0, 2.1, 2.25, 2.5, 2.75]},\n",
    "]\n",
    "cv = purged_kfold.PurgedKFold(train_Y.t1, n_folds=3)\n",
    "cv_iter = cv.split(train_X, train_y)\n",
    "\n",
    "grid_search = GridSearchCV(full_pipeline, param_grid, cv=cv_iter, scoring='neg_root_mean_squared_error')\n",
    "_ = grid_search.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'svr__C': 1.0, 'svr__gamma': 1.5, 'svr__kerne...</td>\n",
       "      <td>-0.034477</td>\n",
       "      <td>0.005459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'svr__C': 30.0, 'svr__gamma': 1.5, 'svr__kern...</td>\n",
       "      <td>-0.034477</td>\n",
       "      <td>0.005459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{'svr__C': 100.0, 'svr__gamma': 1.5, 'svr__ker...</td>\n",
       "      <td>-0.034477</td>\n",
       "      <td>0.005459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>{'svr__C': 1000.0, 'svr__gamma': 1.5, 'svr__ke...</td>\n",
       "      <td>-0.034477</td>\n",
       "      <td>0.005459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'svr__C': 3.0, 'svr__gamma': 1.5, 'svr__kerne...</td>\n",
       "      <td>-0.034477</td>\n",
       "      <td>0.005459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'svr__C': 10.0, 'svr__gamma': 1.5, 'svr__kern...</td>\n",
       "      <td>-0.034477</td>\n",
       "      <td>0.005459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>{'svr__C': 300.0, 'svr__gamma': 1.5, 'svr__ker...</td>\n",
       "      <td>-0.034477</td>\n",
       "      <td>0.005459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'svr__C': 1.0, 'svr__gamma': 1.75, 'svr__kern...</td>\n",
       "      <td>-0.034583</td>\n",
       "      <td>0.005402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'svr__C': 30.0, 'svr__gamma': 1.75, 'svr__ker...</td>\n",
       "      <td>-0.034583</td>\n",
       "      <td>0.005402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>{'svr__C': 100.0, 'svr__gamma': 1.75, 'svr__ke...</td>\n",
       "      <td>-0.034583</td>\n",
       "      <td>0.005402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'svr__C': 10.0, 'svr__gamma': 1.75, 'svr__ker...</td>\n",
       "      <td>-0.034583</td>\n",
       "      <td>0.005402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>{'svr__C': 300.0, 'svr__gamma': 1.75, 'svr__ke...</td>\n",
       "      <td>-0.034583</td>\n",
       "      <td>0.005402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'svr__C': 3.0, 'svr__gamma': 1.75, 'svr__kern...</td>\n",
       "      <td>-0.034583</td>\n",
       "      <td>0.005402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>{'svr__C': 1000.0, 'svr__gamma': 1.75, 'svr__k...</td>\n",
       "      <td>-0.034583</td>\n",
       "      <td>0.005402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>{'svr__C': 300.0, 'svr__gamma': 2.0, 'svr__ker...</td>\n",
       "      <td>-0.034665</td>\n",
       "      <td>0.005359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'svr__C': 3.0, 'svr__gamma': 2.0, 'svr__kerne...</td>\n",
       "      <td>-0.034665</td>\n",
       "      <td>0.005359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'svr__C': 10.0, 'svr__gamma': 2.0, 'svr__kern...</td>\n",
       "      <td>-0.034665</td>\n",
       "      <td>0.005359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>{'svr__C': 100.0, 'svr__gamma': 2.0, 'svr__ker...</td>\n",
       "      <td>-0.034665</td>\n",
       "      <td>0.005359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>{'svr__C': 1000.0, 'svr__gamma': 2.0, 'svr__ke...</td>\n",
       "      <td>-0.034665</td>\n",
       "      <td>0.005359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'svr__C': 1.0, 'svr__gamma': 2.0, 'svr__kerne...</td>\n",
       "      <td>-0.034665</td>\n",
       "      <td>0.005359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'svr__C': 30.0, 'svr__gamma': 2.0, 'svr__kern...</td>\n",
       "      <td>-0.034665</td>\n",
       "      <td>0.005359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>{'svr__C': 300.0, 'svr__gamma': 2.1, 'svr__ker...</td>\n",
       "      <td>-0.034691</td>\n",
       "      <td>0.005345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>{'svr__C': 100.0, 'svr__gamma': 2.1, 'svr__ker...</td>\n",
       "      <td>-0.034691</td>\n",
       "      <td>0.005345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>{'svr__C': 1000.0, 'svr__gamma': 2.1, 'svr__ke...</td>\n",
       "      <td>-0.034691</td>\n",
       "      <td>0.005345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{'svr__C': 30.0, 'svr__gamma': 2.1, 'svr__kern...</td>\n",
       "      <td>-0.034691</td>\n",
       "      <td>0.005345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'svr__C': 3.0, 'svr__gamma': 2.1, 'svr__kerne...</td>\n",
       "      <td>-0.034691</td>\n",
       "      <td>0.005345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'svr__C': 1.0, 'svr__gamma': 2.1, 'svr__kerne...</td>\n",
       "      <td>-0.034691</td>\n",
       "      <td>0.005345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'svr__C': 10.0, 'svr__gamma': 2.1, 'svr__kern...</td>\n",
       "      <td>-0.034691</td>\n",
       "      <td>0.005345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{'svr__C': 30.0, 'svr__gamma': 2.25, 'svr__ker...</td>\n",
       "      <td>-0.034726</td>\n",
       "      <td>0.005327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>{'svr__C': 1000.0, 'svr__gamma': 2.25, 'svr__k...</td>\n",
       "      <td>-0.034726</td>\n",
       "      <td>0.005327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'svr__C': 1.0, 'svr__gamma': 2.25, 'svr__kern...</td>\n",
       "      <td>-0.034726</td>\n",
       "      <td>0.005327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>{'svr__C': 300.0, 'svr__gamma': 2.25, 'svr__ke...</td>\n",
       "      <td>-0.034726</td>\n",
       "      <td>0.005327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'svr__C': 3.0, 'svr__gamma': 2.25, 'svr__kern...</td>\n",
       "      <td>-0.034726</td>\n",
       "      <td>0.005327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>{'svr__C': 100.0, 'svr__gamma': 2.25, 'svr__ke...</td>\n",
       "      <td>-0.034726</td>\n",
       "      <td>0.005327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'svr__C': 10.0, 'svr__gamma': 2.25, 'svr__ker...</td>\n",
       "      <td>-0.034726</td>\n",
       "      <td>0.005327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>{'svr__C': 100.0, 'svr__gamma': 2.5, 'svr__ker...</td>\n",
       "      <td>-0.034773</td>\n",
       "      <td>0.005303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'svr__C': 3.0, 'svr__gamma': 2.5, 'svr__kerne...</td>\n",
       "      <td>-0.034773</td>\n",
       "      <td>0.005303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{'svr__C': 30.0, 'svr__gamma': 2.5, 'svr__kern...</td>\n",
       "      <td>-0.034773</td>\n",
       "      <td>0.005303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>{'svr__C': 300.0, 'svr__gamma': 2.5, 'svr__ker...</td>\n",
       "      <td>-0.034773</td>\n",
       "      <td>0.005303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'svr__C': 1.0, 'svr__gamma': 2.5, 'svr__kerne...</td>\n",
       "      <td>-0.034773</td>\n",
       "      <td>0.005303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'svr__C': 10.0, 'svr__gamma': 2.5, 'svr__kern...</td>\n",
       "      <td>-0.034773</td>\n",
       "      <td>0.005303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>{'svr__C': 1000.0, 'svr__gamma': 2.5, 'svr__ke...</td>\n",
       "      <td>-0.034773</td>\n",
       "      <td>0.005303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>{'svr__C': 100.0, 'svr__gamma': 2.75, 'svr__ke...</td>\n",
       "      <td>-0.034802</td>\n",
       "      <td>0.005291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'svr__C': 3.0, 'svr__gamma': 2.75, 'svr__kern...</td>\n",
       "      <td>-0.034802</td>\n",
       "      <td>0.005291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>{'svr__C': 300.0, 'svr__gamma': 2.75, 'svr__ke...</td>\n",
       "      <td>-0.034802</td>\n",
       "      <td>0.005291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'svr__C': 1.0, 'svr__gamma': 2.75, 'svr__kern...</td>\n",
       "      <td>-0.034802</td>\n",
       "      <td>0.005291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'svr__C': 10.0, 'svr__gamma': 2.75, 'svr__ker...</td>\n",
       "      <td>-0.034802</td>\n",
       "      <td>0.005291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{'svr__C': 30.0, 'svr__gamma': 2.75, 'svr__ker...</td>\n",
       "      <td>-0.034802</td>\n",
       "      <td>0.005291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>{'svr__C': 1000.0, 'svr__gamma': 2.75, 'svr__k...</td>\n",
       "      <td>-0.034802</td>\n",
       "      <td>0.005291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params  mean_test_score  std_test_score\n",
       "0   {'svr__C': 1.0, 'svr__gamma': 1.5, 'svr__kerne...        -0.034477        0.005459\n",
       "21  {'svr__C': 30.0, 'svr__gamma': 1.5, 'svr__kern...        -0.034477        0.005459\n",
       "28  {'svr__C': 100.0, 'svr__gamma': 1.5, 'svr__ker...        -0.034477        0.005459\n",
       "42  {'svr__C': 1000.0, 'svr__gamma': 1.5, 'svr__ke...        -0.034477        0.005459\n",
       "7   {'svr__C': 3.0, 'svr__gamma': 1.5, 'svr__kerne...        -0.034477        0.005459\n",
       "14  {'svr__C': 10.0, 'svr__gamma': 1.5, 'svr__kern...        -0.034477        0.005459\n",
       "35  {'svr__C': 300.0, 'svr__gamma': 1.5, 'svr__ker...        -0.034477        0.005459\n",
       "1   {'svr__C': 1.0, 'svr__gamma': 1.75, 'svr__kern...        -0.034583        0.005402\n",
       "22  {'svr__C': 30.0, 'svr__gamma': 1.75, 'svr__ker...        -0.034583        0.005402\n",
       "29  {'svr__C': 100.0, 'svr__gamma': 1.75, 'svr__ke...        -0.034583        0.005402\n",
       "15  {'svr__C': 10.0, 'svr__gamma': 1.75, 'svr__ker...        -0.034583        0.005402\n",
       "36  {'svr__C': 300.0, 'svr__gamma': 1.75, 'svr__ke...        -0.034583        0.005402\n",
       "8   {'svr__C': 3.0, 'svr__gamma': 1.75, 'svr__kern...        -0.034583        0.005402\n",
       "43  {'svr__C': 1000.0, 'svr__gamma': 1.75, 'svr__k...        -0.034583        0.005402\n",
       "37  {'svr__C': 300.0, 'svr__gamma': 2.0, 'svr__ker...        -0.034665        0.005359\n",
       "9   {'svr__C': 3.0, 'svr__gamma': 2.0, 'svr__kerne...        -0.034665        0.005359\n",
       "16  {'svr__C': 10.0, 'svr__gamma': 2.0, 'svr__kern...        -0.034665        0.005359\n",
       "30  {'svr__C': 100.0, 'svr__gamma': 2.0, 'svr__ker...        -0.034665        0.005359\n",
       "44  {'svr__C': 1000.0, 'svr__gamma': 2.0, 'svr__ke...        -0.034665        0.005359\n",
       "2   {'svr__C': 1.0, 'svr__gamma': 2.0, 'svr__kerne...        -0.034665        0.005359\n",
       "23  {'svr__C': 30.0, 'svr__gamma': 2.0, 'svr__kern...        -0.034665        0.005359\n",
       "38  {'svr__C': 300.0, 'svr__gamma': 2.1, 'svr__ker...        -0.034691        0.005345\n",
       "31  {'svr__C': 100.0, 'svr__gamma': 2.1, 'svr__ker...        -0.034691        0.005345\n",
       "45  {'svr__C': 1000.0, 'svr__gamma': 2.1, 'svr__ke...        -0.034691        0.005345\n",
       "24  {'svr__C': 30.0, 'svr__gamma': 2.1, 'svr__kern...        -0.034691        0.005345\n",
       "10  {'svr__C': 3.0, 'svr__gamma': 2.1, 'svr__kerne...        -0.034691        0.005345\n",
       "3   {'svr__C': 1.0, 'svr__gamma': 2.1, 'svr__kerne...        -0.034691        0.005345\n",
       "17  {'svr__C': 10.0, 'svr__gamma': 2.1, 'svr__kern...        -0.034691        0.005345\n",
       "25  {'svr__C': 30.0, 'svr__gamma': 2.25, 'svr__ker...        -0.034726        0.005327\n",
       "46  {'svr__C': 1000.0, 'svr__gamma': 2.25, 'svr__k...        -0.034726        0.005327\n",
       "4   {'svr__C': 1.0, 'svr__gamma': 2.25, 'svr__kern...        -0.034726        0.005327\n",
       "39  {'svr__C': 300.0, 'svr__gamma': 2.25, 'svr__ke...        -0.034726        0.005327\n",
       "11  {'svr__C': 3.0, 'svr__gamma': 2.25, 'svr__kern...        -0.034726        0.005327\n",
       "32  {'svr__C': 100.0, 'svr__gamma': 2.25, 'svr__ke...        -0.034726        0.005327\n",
       "18  {'svr__C': 10.0, 'svr__gamma': 2.25, 'svr__ker...        -0.034726        0.005327\n",
       "33  {'svr__C': 100.0, 'svr__gamma': 2.5, 'svr__ker...        -0.034773        0.005303\n",
       "12  {'svr__C': 3.0, 'svr__gamma': 2.5, 'svr__kerne...        -0.034773        0.005303\n",
       "26  {'svr__C': 30.0, 'svr__gamma': 2.5, 'svr__kern...        -0.034773        0.005303\n",
       "40  {'svr__C': 300.0, 'svr__gamma': 2.5, 'svr__ker...        -0.034773        0.005303\n",
       "5   {'svr__C': 1.0, 'svr__gamma': 2.5, 'svr__kerne...        -0.034773        0.005303\n",
       "19  {'svr__C': 10.0, 'svr__gamma': 2.5, 'svr__kern...        -0.034773        0.005303\n",
       "47  {'svr__C': 1000.0, 'svr__gamma': 2.5, 'svr__ke...        -0.034773        0.005303\n",
       "34  {'svr__C': 100.0, 'svr__gamma': 2.75, 'svr__ke...        -0.034802        0.005291\n",
       "13  {'svr__C': 3.0, 'svr__gamma': 2.75, 'svr__kern...        -0.034802        0.005291\n",
       "41  {'svr__C': 300.0, 'svr__gamma': 2.75, 'svr__ke...        -0.034802        0.005291\n",
       "6   {'svr__C': 1.0, 'svr__gamma': 2.75, 'svr__kern...        -0.034802        0.005291\n",
       "20  {'svr__C': 10.0, 'svr__gamma': 2.75, 'svr__ker...        -0.034802        0.005291\n",
       "27  {'svr__C': 30.0, 'svr__gamma': 2.75, 'svr__ker...        -0.034802        0.005291\n",
       "48  {'svr__C': 1000.0, 'svr__gamma': 2.75, 'svr__k...        -0.034802        0.005291"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_cv_res = pd.DataFrame(grid_search.cv_results_)\n",
    "svm_cv_res.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "svm_cv_res.loc[:, [\"params\", \"mean_test_score\", \"std_test_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "full_pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocessing()),\n",
    "    (\"xgb\", xgb.XGBRegressor()),\n",
    "])\n",
    "param_grid = [\n",
    "    {\n",
    "        'xgb__max_depth': [1],\n",
    "        'xgb__eta': [0.03, 0.05, 0.06, 0.07, 0.1, 0.3],\n",
    "    },\n",
    "]\n",
    "cv = purged_kfold.PurgedKFold(train_Y.t1, n_folds=3)\n",
    "cv_iter = cv.split(train_X, train_y)\n",
    "\n",
    "grid_search = GridSearchCV(full_pipeline, param_grid, cv=cv_iter, scoring='neg_root_mean_squared_error')\n",
    "_ = grid_search.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'xgb__eta': 0.05, 'xgb__max_depth': 1}</td>\n",
       "      <td>-0.034598</td>\n",
       "      <td>0.004533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'xgb__eta': 0.06, 'xgb__max_depth': 1}</td>\n",
       "      <td>-0.034888</td>\n",
       "      <td>0.004569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'xgb__eta': 0.07, 'xgb__max_depth': 1}</td>\n",
       "      <td>-0.035209</td>\n",
       "      <td>0.004448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'xgb__eta': 0.1, 'xgb__max_depth': 1}</td>\n",
       "      <td>-0.035682</td>\n",
       "      <td>0.004143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'xgb__eta': 0.3, 'xgb__max_depth': 1}</td>\n",
       "      <td>-0.037149</td>\n",
       "      <td>0.003496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'xgb__eta': 0.03, 'xgb__max_depth': 1}</td>\n",
       "      <td>-0.039916</td>\n",
       "      <td>0.005008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    params  mean_test_score  std_test_score\n",
       "1  {'xgb__eta': 0.05, 'xgb__max_depth': 1}        -0.034598        0.004533\n",
       "2  {'xgb__eta': 0.06, 'xgb__max_depth': 1}        -0.034888        0.004569\n",
       "3  {'xgb__eta': 0.07, 'xgb__max_depth': 1}        -0.035209        0.004448\n",
       "4   {'xgb__eta': 0.1, 'xgb__max_depth': 1}        -0.035682        0.004143\n",
       "5   {'xgb__eta': 0.3, 'xgb__max_depth': 1}        -0.037149        0.003496\n",
       "0  {'xgb__eta': 0.03, 'xgb__max_depth': 1}        -0.039916        0.005008"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cv_res = pd.DataFrame(grid_search.cv_results_)\n",
    "xgb_cv_res.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "xgb_cv_res.loc[:, [\"params\", \"mean_test_score\", \"std_test_score\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "## Select and Train a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cls_train_Y = train_Y.assign(vug_vtv_60d_ret=np.sign(train_Y.vug_vtv_60d_ret).clip(0, 1), w=train_Y.vug_vtv_60d_ret\n",
    "                             .abs())\n",
    "cls_train_y = cls_train_Y.vug_vtv_60d_ret\n",
    "cls_train_w = cls_train_Y.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t1</th>\n",
       "      <th>w</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vug_vtv_60d_ret</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>1488</td>\n",
       "      <td>1488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1803</td>\n",
       "      <td>1803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   t1     w\n",
       "vug_vtv_60d_ret            \n",
       "0.0              1488  1488\n",
       "1.0              1803  1803"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = cls_train_Y.groupby(\"vug_vtv_60d_ret\").count()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5478577939835916"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your success rate if you just guessed positive.\n",
    "guess_positive_accuracy = counts.loc[1.0, :].t1 / counts.t1.sum()\n",
    "guess_positive_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6201794349888833, 0.6241172398239985)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "\n",
    "log_reg = make_pipeline(preprocessing(), LogisticRegression())\n",
    "log_reg.fit(train_X, cls_train_y, logisticregression__sample_weight=cls_train_w)\n",
    "predicted_probs = log_reg.predict_proba(train_X)\n",
    "predicted_class = log_reg.predict(train_X)\n",
    "log_loss_ = log_loss(cls_train_y, predicted_probs, sample_weight=cls_train_w)\n",
    "log_accuracy = accuracy_score(cls_train_y, predicted_class, sample_weight=cls_train_w)\n",
    "log_loss_, log_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg_log_loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.755882</td>\n",
       "      <td>0.512251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.106812</td>\n",
       "      <td>0.132271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      neg_log_loss  accuracy\n",
       "mean     -0.755882  0.512251\n",
       "std       0.106812  0.132271"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_func = Pipeline([(\"standardize\", StandardScaler()), ('log', LogisticRegression())])\n",
    "scores = purged_kfold.cv_score(log_reg_func, train_X, cls_train_Y, n_folds=3, scoring=[\"neg_log_loss\", \"accuracy\"],\n",
    "                               has_weights=True)\n",
    "scores.agg([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.09833784116993635, 1.0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_reg = make_pipeline(preprocessing(), RandomForestClassifier())\n",
    "forest_reg.fit(train_X, cls_train_y, randomforestclassifier__sample_weight=cls_train_w)\n",
    "predicted_probs = forest_reg.predict_proba(train_X)\n",
    "predicted_class = forest_reg.predict(train_X)\n",
    "forest_loss = log_loss(cls_train_y, predicted_probs, sample_weight=cls_train_w)\n",
    "forest_accuracy = accuracy_score(cls_train_y, predicted_class, sample_weight=cls_train_w)\n",
    "forest_loss, forest_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg_log_loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.867198</td>\n",
       "      <td>0.528308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.118149</td>\n",
       "      <td>0.069525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      neg_log_loss  accuracy\n",
       "mean     -0.867198  0.528308\n",
       "std       0.118149  0.069525"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_cls_func = Pipeline([(\"standardize\", StandardScaler()), ('log', RandomForestClassifier())])\n",
    "scores = purged_kfold.cv_score(forest_cls_func, train_X, cls_train_Y, n_folds=3, scoring=[\"neg_log_loss\", \"accuracy\"],\n",
    "                               has_weights=True)\n",
    "scores.agg([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5673400957654541, 0.6873481237309548)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_cls = make_pipeline(preprocessing(), SVC(probability=True))\n",
    "svm_cls.fit(train_X, cls_train_y, svc__sample_weight=cls_train_w)\n",
    "predicted_probs = svm_cls.predict_proba(train_X)\n",
    "predicted_class = svm_cls.predict(train_X)\n",
    "svm_loss = log_loss(cls_train_y, predicted_probs, sample_weight=cls_train_w)\n",
    "svm_accuracy = accuracy_score(cls_train_y, predicted_class, sample_weight=cls_train_w)\n",
    "svm_loss, svm_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg_log_loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.756013</td>\n",
       "      <td>0.487998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.019573</td>\n",
       "      <td>0.030238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      neg_log_loss  accuracy\n",
       "mean     -0.756013  0.487998\n",
       "std       0.019573  0.030238"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_cls_func = Pipeline([(\"standardize\", StandardScaler()), ('svc', SVC(probability=True))])\n",
    "cv_gen = purged_kfold.PurgedKFold(cls_train_Y.t1, 3)\n",
    "scores = purged_kfold.cv_score(svc_cls_func, train_X, cls_train_Y, cv_gen=cv_gen, scoring=[\"neg_log_loss\", \"accuracy\"], has_weights=True)\n",
    "scores.agg([\"mean\", \"std\"])\n",
    "#scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.32001637946255607, 0.8661235005652731)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cls = make_pipeline(preprocessing(), xgb.XGBClassifier())\n",
    "xgb_cls.fit(train_X, cls_train_y, xgbclassifier__sample_weight=cls_train_w)\n",
    "predicted_probs = xgb_cls.predict_proba(train_X)\n",
    "predicted_class = xgb_cls.predict(train_X)\n",
    "xgb_loss = log_loss(cls_train_y, predicted_probs, sample_weight=cls_train_w)\n",
    "xgb_accuracy = accuracy_score(cls_train_y, predicted_class, sample_weight=cls_train_w)\n",
    "xgb_loss, xgb_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg_log_loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.878299</td>\n",
       "      <td>0.494194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.089502</td>\n",
       "      <td>0.039329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      neg_log_loss  accuracy\n",
       "mean     -0.878299  0.494194\n",
       "std       0.089502  0.039329"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cls_func = lambda: Pipeline([(\"standardize\", StandardScaler()), ('xgb', xgb.XGBClassifier())])\n",
    "scores = purged_kfold.cv_score(xgb_cls_func, train_X, cls_train_Y, n_folds=3, scoring=[\"neg_log_loss\", \"accuracy\"],\n",
    "                               has_weights=True)\n",
    "scores.agg([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tune your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "full_pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocessing()),\n",
    "    (\"random_forest\", RandomForestClassifier(random_state=42, max_features=None)),\n",
    "])\n",
    "param_grid = [\n",
    "    {\n",
    "        'random_forest__max_depth': [1, 2, 4],\n",
    "        'random_forest__n_estimators': [10, 100, 1000],\n",
    "    },\n",
    "]\n",
    "cv = purged_kfold.PurgedKFold(train_Y.t1, n_folds=3)\n",
    "cv_iter = cv.split(train_X, cls_train_y)\n",
    "\n",
    "grid_search = GridSearchCV(full_pipeline, param_grid, cv=cv_iter, scoring='accuracy')\n",
    "_ = grid_search.fit(train_X, cls_train_y)#, random_forest__sample_weight=cls_train_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'random_forest__max_depth': 1, 'random_forest...</td>\n",
       "      <td>0.455789</td>\n",
       "      <td>0.019819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'random_forest__max_depth': 1, 'random_forest...</td>\n",
       "      <td>0.454877</td>\n",
       "      <td>0.022192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'random_forest__max_depth': 1, 'random_forest...</td>\n",
       "      <td>0.454573</td>\n",
       "      <td>0.021857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'random_forest__max_depth': 2, 'random_forest...</td>\n",
       "      <td>0.452446</td>\n",
       "      <td>0.024689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'random_forest__max_depth': 4, 'random_forest...</td>\n",
       "      <td>0.437861</td>\n",
       "      <td>0.019414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'random_forest__max_depth': 2, 'random_forest...</td>\n",
       "      <td>0.435734</td>\n",
       "      <td>0.028605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'random_forest__max_depth': 2, 'random_forest...</td>\n",
       "      <td>0.431176</td>\n",
       "      <td>0.034327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'random_forest__max_depth': 4, 'random_forest...</td>\n",
       "      <td>0.424491</td>\n",
       "      <td>0.023077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'random_forest__max_depth': 4, 'random_forest...</td>\n",
       "      <td>0.421149</td>\n",
       "      <td>0.025042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params  mean_test_score  std_test_score\n",
       "0  {'random_forest__max_depth': 1, 'random_forest...         0.455789        0.019819\n",
       "1  {'random_forest__max_depth': 1, 'random_forest...         0.454877        0.022192\n",
       "2  {'random_forest__max_depth': 1, 'random_forest...         0.454573        0.021857\n",
       "3  {'random_forest__max_depth': 2, 'random_forest...         0.452446        0.024689\n",
       "6  {'random_forest__max_depth': 4, 'random_forest...         0.437861        0.019414\n",
       "5  {'random_forest__max_depth': 2, 'random_forest...         0.435734        0.028605\n",
       "4  {'random_forest__max_depth': 2, 'random_forest...         0.431176        0.034327\n",
       "7  {'random_forest__max_depth': 4, 'random_forest...         0.424491        0.023077\n",
       "8  {'random_forest__max_depth': 4, 'random_forest...         0.421149        0.025042"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_res.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "cv_res.loc[:, [\"params\", \"mean_test_score\", \"std_test_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "full_pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocessing()),\n",
    "    (\"svc\", SVC()),\n",
    "])\n",
    "param_grid = [\n",
    "    {'svc__kernel': ['linear'], 'svc__C': [10., 30., 100., 300., 1000.,\n",
    "                                           3000., 10000., 30000.0]},\n",
    "    {'svc__kernel': ['rbf'], 'svc__C': [1.0, 3.0, 10., 30., 100., 300.,\n",
    "                                        1000.0],\n",
    "     'svc__gamma': [0.01, 0.03, 0.1, 0.3, 1.0, 3.0]},\n",
    "]\n",
    "cv = purged_kfold.PurgedKFold(train_Y.t1, n_folds=3)\n",
    "cv_iter = cv.split(train_X, cls_train_y)\n",
    "\n",
    "grid_search = GridSearchCV(full_pipeline, param_grid, cv=cv_iter, scoring='accuracy')\n",
    "_ = grid_search.fit(train_X, cls_train_y, svc__sample_weight=cls_train_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'svc__C': 1.0, 'svc__gamma': 0.01, 'svc__kern...</td>\n",
       "      <td>0.547858</td>\n",
       "      <td>0.035407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'svc__C': 1.0, 'svc__gamma': 3.0, 'svc__kerne...</td>\n",
       "      <td>0.543300</td>\n",
       "      <td>0.021469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>{'svc__C': 300.0, 'svc__gamma': 0.3, 'svc__ker...</td>\n",
       "      <td>0.534488</td>\n",
       "      <td>0.033322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>{'svc__C': 30.0, 'svc__gamma': 3.0, 'svc__kern...</td>\n",
       "      <td>0.527803</td>\n",
       "      <td>0.023525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{'svc__C': 10.0, 'svc__gamma': 3.0, 'svc__kern...</td>\n",
       "      <td>0.526284</td>\n",
       "      <td>0.022739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{'svc__C': 10.0, 'svc__gamma': 1.0, 'svc__kern...</td>\n",
       "      <td>0.525372</td>\n",
       "      <td>0.028801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>{'svc__C': 1000.0, 'svc__gamma': 0.3, 'svc__ke...</td>\n",
       "      <td>0.524461</td>\n",
       "      <td>0.035636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>{'svc__C': 1000.0, 'svc__gamma': 3.0, 'svc__ke...</td>\n",
       "      <td>0.523549</td>\n",
       "      <td>0.033760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>{'svc__C': 100.0, 'svc__gamma': 3.0, 'svc__ker...</td>\n",
       "      <td>0.523549</td>\n",
       "      <td>0.030365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>{'svc__C': 300.0, 'svc__gamma': 3.0, 'svc__ker...</td>\n",
       "      <td>0.523245</td>\n",
       "      <td>0.030571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'svc__C': 3.0, 'svc__gamma': 3.0, 'svc__kerne...</td>\n",
       "      <td>0.522941</td>\n",
       "      <td>0.014611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>{'svc__C': 100.0, 'svc__gamma': 0.3, 'svc__ker...</td>\n",
       "      <td>0.520814</td>\n",
       "      <td>0.020415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>{'svc__C': 30.0, 'svc__gamma': 0.3, 'svc__kern...</td>\n",
       "      <td>0.519599</td>\n",
       "      <td>0.021928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>{'svc__C': 30.0, 'svc__gamma': 1.0, 'svc__kern...</td>\n",
       "      <td>0.519599</td>\n",
       "      <td>0.031163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'svc__C': 10.0, 'svc__gamma': 0.3, 'svc__kern...</td>\n",
       "      <td>0.518991</td>\n",
       "      <td>0.024913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>{'svc__C': 300.0, 'svc__gamma': 0.1, 'svc__ker...</td>\n",
       "      <td>0.517472</td>\n",
       "      <td>0.007492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>{'svc__C': 1000.0, 'svc__gamma': 0.1, 'svc__ke...</td>\n",
       "      <td>0.516560</td>\n",
       "      <td>0.011296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'svc__C': 3.0, 'svc__gamma': 1.0, 'svc__kerne...</td>\n",
       "      <td>0.515649</td>\n",
       "      <td>0.017650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>{'svc__C': 1000.0, 'svc__gamma': 1.0, 'svc__ke...</td>\n",
       "      <td>0.514737</td>\n",
       "      <td>0.028695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'svc__C': 1.0, 'svc__gamma': 1.0, 'svc__kerne...</td>\n",
       "      <td>0.512914</td>\n",
       "      <td>0.011048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>{'svc__C': 100.0, 'svc__gamma': 1.0, 'svc__ker...</td>\n",
       "      <td>0.512306</td>\n",
       "      <td>0.025880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>{'svc__C': 300.0, 'svc__gamma': 1.0, 'svc__ker...</td>\n",
       "      <td>0.512306</td>\n",
       "      <td>0.024607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>{'svc__C': 100.0, 'svc__gamma': 0.1, 'svc__ker...</td>\n",
       "      <td>0.511091</td>\n",
       "      <td>0.006916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>{'svc__C': 1000.0, 'svc__gamma': 0.03, 'svc__k...</td>\n",
       "      <td>0.509572</td>\n",
       "      <td>0.022710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'svc__C': 10.0, 'svc__gamma': 0.03, 'svc__ker...</td>\n",
       "      <td>0.505014</td>\n",
       "      <td>0.049701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'svc__C': 3.0, 'svc__gamma': 0.3, 'svc__kerne...</td>\n",
       "      <td>0.504406</td>\n",
       "      <td>0.031528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{'svc__C': 30.0, 'svc__gamma': 0.1, 'svc__kern...</td>\n",
       "      <td>0.497721</td>\n",
       "      <td>0.025394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'svc__C': 3.0, 'svc__gamma': 0.1, 'svc__kerne...</td>\n",
       "      <td>0.493163</td>\n",
       "      <td>0.049163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{'svc__C': 30.0, 'svc__gamma': 0.01, 'svc__ker...</td>\n",
       "      <td>0.491340</td>\n",
       "      <td>0.042150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'svc__C': 10.0, 'svc__gamma': 0.1, 'svc__kern...</td>\n",
       "      <td>0.489213</td>\n",
       "      <td>0.039359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>{'svc__C': 300.0, 'svc__gamma': 0.03, 'svc__ke...</td>\n",
       "      <td>0.489213</td>\n",
       "      <td>0.015917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'svc__C': 1.0, 'svc__gamma': 0.3, 'svc__kerne...</td>\n",
       "      <td>0.483744</td>\n",
       "      <td>0.026171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'svc__C': 3.0, 'svc__gamma': 0.03, 'svc__kern...</td>\n",
       "      <td>0.481920</td>\n",
       "      <td>0.031379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'svc__C': 1.0, 'svc__gamma': 0.1, 'svc__kerne...</td>\n",
       "      <td>0.479490</td>\n",
       "      <td>0.036788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'svc__C': 10.0, 'svc__gamma': 0.01, 'svc__ker...</td>\n",
       "      <td>0.478882</td>\n",
       "      <td>0.030592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'svc__C': 10.0, 'svc__kernel': 'linear'}</td>\n",
       "      <td>0.474324</td>\n",
       "      <td>0.029438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'svc__C': 10000.0, 'svc__kernel': 'linear'}</td>\n",
       "      <td>0.474324</td>\n",
       "      <td>0.028907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'svc__C': 1000.0, 'svc__kernel': 'linear'}</td>\n",
       "      <td>0.474020</td>\n",
       "      <td>0.029322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'svc__C': 300.0, 'svc__kernel': 'linear'}</td>\n",
       "      <td>0.474020</td>\n",
       "      <td>0.029322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'svc__C': 30.0, 'svc__kernel': 'linear'}</td>\n",
       "      <td>0.474020</td>\n",
       "      <td>0.029322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'svc__C': 3000.0, 'svc__kernel': 'linear'}</td>\n",
       "      <td>0.474020</td>\n",
       "      <td>0.029322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'svc__C': 100.0, 'svc__kernel': 'linear'}</td>\n",
       "      <td>0.474020</td>\n",
       "      <td>0.029322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'svc__C': 30000.0, 'svc__kernel': 'linear'}</td>\n",
       "      <td>0.474020</td>\n",
       "      <td>0.029322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>{'svc__C': 100.0, 'svc__gamma': 0.01, 'svc__ke...</td>\n",
       "      <td>0.469766</td>\n",
       "      <td>0.033653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{'svc__C': 30.0, 'svc__gamma': 0.03, 'svc__ker...</td>\n",
       "      <td>0.467943</td>\n",
       "      <td>0.026591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'svc__C': 3.0, 'svc__gamma': 0.01, 'svc__kern...</td>\n",
       "      <td>0.467335</td>\n",
       "      <td>0.030592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'svc__C': 1.0, 'svc__gamma': 0.03, 'svc__kern...</td>\n",
       "      <td>0.462777</td>\n",
       "      <td>0.029438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>{'svc__C': 100.0, 'svc__gamma': 0.03, 'svc__ke...</td>\n",
       "      <td>0.461258</td>\n",
       "      <td>0.027113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>{'svc__C': 300.0, 'svc__gamma': 0.01, 'svc__ke...</td>\n",
       "      <td>0.459131</td>\n",
       "      <td>0.032497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>{'svc__C': 1000.0, 'svc__gamma': 0.01, 'svc__k...</td>\n",
       "      <td>0.455485</td>\n",
       "      <td>0.029231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params  mean_test_score  std_test_score\n",
       "8   {'svc__C': 1.0, 'svc__gamma': 0.01, 'svc__kern...         0.547858        0.035407\n",
       "13  {'svc__C': 1.0, 'svc__gamma': 3.0, 'svc__kerne...         0.543300        0.021469\n",
       "41  {'svc__C': 300.0, 'svc__gamma': 0.3, 'svc__ker...         0.534488        0.033322\n",
       "31  {'svc__C': 30.0, 'svc__gamma': 3.0, 'svc__kern...         0.527803        0.023525\n",
       "25  {'svc__C': 10.0, 'svc__gamma': 3.0, 'svc__kern...         0.526284        0.022739\n",
       "24  {'svc__C': 10.0, 'svc__gamma': 1.0, 'svc__kern...         0.525372        0.028801\n",
       "47  {'svc__C': 1000.0, 'svc__gamma': 0.3, 'svc__ke...         0.524461        0.035636\n",
       "49  {'svc__C': 1000.0, 'svc__gamma': 3.0, 'svc__ke...         0.523549        0.033760\n",
       "37  {'svc__C': 100.0, 'svc__gamma': 3.0, 'svc__ker...         0.523549        0.030365\n",
       "43  {'svc__C': 300.0, 'svc__gamma': 3.0, 'svc__ker...         0.523245        0.030571\n",
       "19  {'svc__C': 3.0, 'svc__gamma': 3.0, 'svc__kerne...         0.522941        0.014611\n",
       "35  {'svc__C': 100.0, 'svc__gamma': 0.3, 'svc__ker...         0.520814        0.020415\n",
       "29  {'svc__C': 30.0, 'svc__gamma': 0.3, 'svc__kern...         0.519599        0.021928\n",
       "30  {'svc__C': 30.0, 'svc__gamma': 1.0, 'svc__kern...         0.519599        0.031163\n",
       "23  {'svc__C': 10.0, 'svc__gamma': 0.3, 'svc__kern...         0.518991        0.024913\n",
       "40  {'svc__C': 300.0, 'svc__gamma': 0.1, 'svc__ker...         0.517472        0.007492\n",
       "46  {'svc__C': 1000.0, 'svc__gamma': 0.1, 'svc__ke...         0.516560        0.011296\n",
       "18  {'svc__C': 3.0, 'svc__gamma': 1.0, 'svc__kerne...         0.515649        0.017650\n",
       "48  {'svc__C': 1000.0, 'svc__gamma': 1.0, 'svc__ke...         0.514737        0.028695\n",
       "12  {'svc__C': 1.0, 'svc__gamma': 1.0, 'svc__kerne...         0.512914        0.011048\n",
       "36  {'svc__C': 100.0, 'svc__gamma': 1.0, 'svc__ker...         0.512306        0.025880\n",
       "42  {'svc__C': 300.0, 'svc__gamma': 1.0, 'svc__ker...         0.512306        0.024607\n",
       "34  {'svc__C': 100.0, 'svc__gamma': 0.1, 'svc__ker...         0.511091        0.006916\n",
       "45  {'svc__C': 1000.0, 'svc__gamma': 0.03, 'svc__k...         0.509572        0.022710\n",
       "21  {'svc__C': 10.0, 'svc__gamma': 0.03, 'svc__ker...         0.505014        0.049701\n",
       "17  {'svc__C': 3.0, 'svc__gamma': 0.3, 'svc__kerne...         0.504406        0.031528\n",
       "28  {'svc__C': 30.0, 'svc__gamma': 0.1, 'svc__kern...         0.497721        0.025394\n",
       "16  {'svc__C': 3.0, 'svc__gamma': 0.1, 'svc__kerne...         0.493163        0.049163\n",
       "26  {'svc__C': 30.0, 'svc__gamma': 0.01, 'svc__ker...         0.491340        0.042150\n",
       "22  {'svc__C': 10.0, 'svc__gamma': 0.1, 'svc__kern...         0.489213        0.039359\n",
       "39  {'svc__C': 300.0, 'svc__gamma': 0.03, 'svc__ke...         0.489213        0.015917\n",
       "11  {'svc__C': 1.0, 'svc__gamma': 0.3, 'svc__kerne...         0.483744        0.026171\n",
       "15  {'svc__C': 3.0, 'svc__gamma': 0.03, 'svc__kern...         0.481920        0.031379\n",
       "10  {'svc__C': 1.0, 'svc__gamma': 0.1, 'svc__kerne...         0.479490        0.036788\n",
       "20  {'svc__C': 10.0, 'svc__gamma': 0.01, 'svc__ker...         0.478882        0.030592\n",
       "0           {'svc__C': 10.0, 'svc__kernel': 'linear'}         0.474324        0.029438\n",
       "6        {'svc__C': 10000.0, 'svc__kernel': 'linear'}         0.474324        0.028907\n",
       "4         {'svc__C': 1000.0, 'svc__kernel': 'linear'}         0.474020        0.029322\n",
       "3          {'svc__C': 300.0, 'svc__kernel': 'linear'}         0.474020        0.029322\n",
       "1           {'svc__C': 30.0, 'svc__kernel': 'linear'}         0.474020        0.029322\n",
       "5         {'svc__C': 3000.0, 'svc__kernel': 'linear'}         0.474020        0.029322\n",
       "2          {'svc__C': 100.0, 'svc__kernel': 'linear'}         0.474020        0.029322\n",
       "7        {'svc__C': 30000.0, 'svc__kernel': 'linear'}         0.474020        0.029322\n",
       "32  {'svc__C': 100.0, 'svc__gamma': 0.01, 'svc__ke...         0.469766        0.033653\n",
       "27  {'svc__C': 30.0, 'svc__gamma': 0.03, 'svc__ker...         0.467943        0.026591\n",
       "14  {'svc__C': 3.0, 'svc__gamma': 0.01, 'svc__kern...         0.467335        0.030592\n",
       "9   {'svc__C': 1.0, 'svc__gamma': 0.03, 'svc__kern...         0.462777        0.029438\n",
       "33  {'svc__C': 100.0, 'svc__gamma': 0.03, 'svc__ke...         0.461258        0.027113\n",
       "38  {'svc__C': 300.0, 'svc__gamma': 0.01, 'svc__ke...         0.459131        0.032497\n",
       "44  {'svc__C': 1000.0, 'svc__gamma': 0.01, 'svc__k...         0.455485        0.029231"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_res.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "cv_res.loc[:, [\"params\", \"mean_test_score\", \"std_test_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "full_pipeline = Pipeline([(\"standardize\", StandardScaler()), ('svc', SVC(probability=True))])\n",
    "param_grid = [\n",
    "    {'svc__C': [1.0, 2, 5, 10]},\n",
    "]\n",
    "cv = purged_kfold.PurgedKFold(cls_train_Y.t1, n_folds=3)\n",
    "grid_search = GridSearchCV(full_pipeline, param_grid, cv=cv, scoring=['neg_log_loss', 'accuracy'], refit=\"neg_log_loss\")\n",
    "_ = grid_search.fit(train_X, cls_train_y)#, standardize__sample_weight=cls_train_w)#, svc__sample_weight=cls_train_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>std_test_neg_log_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'svc__C': 2}</td>\n",
       "      <td>0.529626</td>\n",
       "      <td>0.025686</td>\n",
       "      <td>-0.788260</td>\n",
       "      <td>0.023074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'svc__C': 10}</td>\n",
       "      <td>0.528411</td>\n",
       "      <td>0.031651</td>\n",
       "      <td>-0.903147</td>\n",
       "      <td>0.040774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'svc__C': 1.0}</td>\n",
       "      <td>0.526588</td>\n",
       "      <td>0.024689</td>\n",
       "      <td>-0.766461</td>\n",
       "      <td>0.024327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'svc__C': 5}</td>\n",
       "      <td>0.524765</td>\n",
       "      <td>0.027147</td>\n",
       "      <td>-0.844637</td>\n",
       "      <td>0.017397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            params  mean_test_accuracy  std_test_accuracy  mean_test_neg_log_loss  std_test_neg_log_loss\n",
       "1    {'svc__C': 2}            0.529626           0.025686               -0.788260               0.023074\n",
       "3   {'svc__C': 10}            0.528411           0.031651               -0.903147               0.040774\n",
       "0  {'svc__C': 1.0}            0.526588           0.024689               -0.766461               0.024327\n",
       "2    {'svc__C': 5}            0.524765           0.027147               -0.844637               0.017397"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_res.sort_values(by=\"mean_test_accuracy\", ascending=False, inplace=True)\n",
    "cv_res.loc[:, [\"params\", \"mean_test_accuracy\", \"std_test_accuracy\", \"mean_test_neg_log_loss\", \"std_test_neg_log_loss\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "full_pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocessing()),\n",
    "    (\"xgb\", xgb.XGBClassifier()),\n",
    "])\n",
    "param_grid = [\n",
    "    {\n",
    "        'xgb__max_depth': [1, 3, 4],\n",
    "        'xgb__eta': [0.03, 0.05, 0.06, 0.07, 0.1, 0.3],\n",
    "    },\n",
    "]\n",
    "cv = purged_kfold.PurgedKFold(train_Y.t1, n_folds=3)\n",
    "cv_iter = cv.split(train_X, cls_train_y)\n",
    "\n",
    "grid_search = GridSearchCV(full_pipeline, param_grid, cv=cv_iter, scoring='accuracy')\n",
    "_ = grid_search.fit(train_X, cls_train_y)#, xgb__sample_weight=cls_train_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'xgb__eta': 0.1, 'xgb__max_depth': 1}</td>\n",
       "      <td>0.522334</td>\n",
       "      <td>0.061642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'xgb__eta': 0.05, 'xgb__max_depth': 1}</td>\n",
       "      <td>0.519903</td>\n",
       "      <td>0.062788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'xgb__eta': 0.07, 'xgb__max_depth': 1}</td>\n",
       "      <td>0.517472</td>\n",
       "      <td>0.061971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'xgb__eta': 0.03, 'xgb__max_depth': 1}</td>\n",
       "      <td>0.516256</td>\n",
       "      <td>0.045043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'xgb__eta': 0.06, 'xgb__max_depth': 1}</td>\n",
       "      <td>0.508356</td>\n",
       "      <td>0.046483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'xgb__eta': 0.3, 'xgb__max_depth': 4}</td>\n",
       "      <td>0.506229</td>\n",
       "      <td>0.042080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'xgb__eta': 0.3, 'xgb__max_depth': 3}</td>\n",
       "      <td>0.504102</td>\n",
       "      <td>0.047127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'xgb__eta': 0.3, 'xgb__max_depth': 1}</td>\n",
       "      <td>0.503798</td>\n",
       "      <td>0.072524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'xgb__eta': 0.1, 'xgb__max_depth': 4}</td>\n",
       "      <td>0.503494</td>\n",
       "      <td>0.073003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'xgb__eta': 0.06, 'xgb__max_depth': 4}</td>\n",
       "      <td>0.499240</td>\n",
       "      <td>0.076320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'xgb__eta': 0.06, 'xgb__max_depth': 3}</td>\n",
       "      <td>0.497417</td>\n",
       "      <td>0.059713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'xgb__eta': 0.07, 'xgb__max_depth': 4}</td>\n",
       "      <td>0.497417</td>\n",
       "      <td>0.076603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'xgb__eta': 0.1, 'xgb__max_depth': 3}</td>\n",
       "      <td>0.497113</td>\n",
       "      <td>0.060514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'xgb__eta': 0.07, 'xgb__max_depth': 3}</td>\n",
       "      <td>0.495898</td>\n",
       "      <td>0.066518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'xgb__eta': 0.05, 'xgb__max_depth': 4}</td>\n",
       "      <td>0.493163</td>\n",
       "      <td>0.078251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'xgb__eta': 0.05, 'xgb__max_depth': 3}</td>\n",
       "      <td>0.487694</td>\n",
       "      <td>0.063606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'xgb__eta': 0.03, 'xgb__max_depth': 4}</td>\n",
       "      <td>0.485871</td>\n",
       "      <td>0.078144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'xgb__eta': 0.03, 'xgb__max_depth': 3}</td>\n",
       "      <td>0.484351</td>\n",
       "      <td>0.047275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  std_test_score\n",
       "12   {'xgb__eta': 0.1, 'xgb__max_depth': 1}         0.522334        0.061642\n",
       "3   {'xgb__eta': 0.05, 'xgb__max_depth': 1}         0.519903        0.062788\n",
       "9   {'xgb__eta': 0.07, 'xgb__max_depth': 1}         0.517472        0.061971\n",
       "0   {'xgb__eta': 0.03, 'xgb__max_depth': 1}         0.516256        0.045043\n",
       "6   {'xgb__eta': 0.06, 'xgb__max_depth': 1}         0.508356        0.046483\n",
       "17   {'xgb__eta': 0.3, 'xgb__max_depth': 4}         0.506229        0.042080\n",
       "16   {'xgb__eta': 0.3, 'xgb__max_depth': 3}         0.504102        0.047127\n",
       "15   {'xgb__eta': 0.3, 'xgb__max_depth': 1}         0.503798        0.072524\n",
       "14   {'xgb__eta': 0.1, 'xgb__max_depth': 4}         0.503494        0.073003\n",
       "8   {'xgb__eta': 0.06, 'xgb__max_depth': 4}         0.499240        0.076320\n",
       "7   {'xgb__eta': 0.06, 'xgb__max_depth': 3}         0.497417        0.059713\n",
       "11  {'xgb__eta': 0.07, 'xgb__max_depth': 4}         0.497417        0.076603\n",
       "13   {'xgb__eta': 0.1, 'xgb__max_depth': 3}         0.497113        0.060514\n",
       "10  {'xgb__eta': 0.07, 'xgb__max_depth': 3}         0.495898        0.066518\n",
       "5   {'xgb__eta': 0.05, 'xgb__max_depth': 4}         0.493163        0.078251\n",
       "4   {'xgb__eta': 0.05, 'xgb__max_depth': 3}         0.487694        0.063606\n",
       "2   {'xgb__eta': 0.03, 'xgb__max_depth': 4}         0.485871        0.078144\n",
       "1   {'xgb__eta': 0.03, 'xgb__max_depth': 3}         0.484351        0.047275"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_res.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "cv_res.loc[:, [\"params\", \"mean_test_score\", \"std_test_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
